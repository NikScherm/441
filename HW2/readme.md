Reflect on what I created and compare to what GPT/copilot created for me:

I used Copilot, the result that it gave me was precicely what was needed from a technical point of view, obviously the answers were not, but I would have needed to be specific about the answers that I wanted for these. The code being quite simple, it did not make any errors. 

•If I were to use it to generate and output, my feelings on this matter would differ greatly depending on what I need it for and what it is able to produce.
For example, if the code was simple, trivial, and mundane, and well within my scope of knowledge I would have no issue using it to speed up the process.
In order to learn the best way is to put into practice, so by outsourcing the thinking to copilot I am essentially not thinking for myself and it would yield a lesser understand when
trying to think of creative solutions to my projects.

•Currently, the code written for me, is well within my current level of knowledge and I don't have any issue explaining it. If there comes a time when it produces code that I am unfamiliar with
I will simply try to break it down line by line until I fully understand how it works all together. In doing so, I will learn how to better put these pieces together on a larger scale in order to think up creative solutions to problems that I may be confronted with.

•From my understanding, before LLM's were this advanced. Many would learn by breaking down code made by others on github or stackexchange, and implementing parts that they needed into their own project, the work is still mine so long as I use it to fulfill my own vision, however blindly doing so would make me feel as if I had no control over what I wanted to implement, leading me to feel like the work would not be mine. I can see the line getting blurry as the amount of code and problems solved increases in volume. 

I think it's a good tool and can teach you many things if prompted correctly. 